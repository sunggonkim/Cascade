# Cascade: HPC 스케일 LLM 추론을 위한 KV 캐시 스토리지 시스템

> **SC'26 논문** | NERSC Perlmutter | A100 GPU | Slingshot-11

---

## 🎯 문제 정의

LLM 추론은 **메모리 바운드**: 전체 시간의 80%가 KV 캐시 로딩에 소비됩니다.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    LLM 추론 시간 분석 (LLaMA-70B)                        │
├─────────────────────────────────────────────────────────────────────────┤
│ ████████████████████████████████████████░░░░░░░░░░ KV 캐시 로딩 (80%)   │
│ ░░░░░░░░░░ 연산 (20%)                                                   │
└─────────────────────────────────────────────────────────────────────────┘
```

### 기존 시스템들의 한계

| 시스템 | 유형 | 한계점 | HPC 스케일 문제 |
|--------|------|--------|----------------|
| **vLLM** | GPU 메모리 | GPU당 40GB 제한 | ❌ 멀티노드 불가 |
| **LMCache** | 파일 기반 | 세션별 중복 저장 | ❌ 싱글노드 전용 |
| **PDC** | 객체 스토리지 | fsync 오버헤드 | ⚠️ 쓰기 느림 |
| **Redis** | 인메모리 KV | 네트워크 직렬화 | ❌ 싱글노드 전용 |
| **HDF5** | 과학 데이터 | 압축 CPU 병목 | ❌ 너무 느림 |

---

## 🚀 Cascade의 해결책

### 4계층 계층적 스토리지

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         Cascade 아키텍처                                 │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│   Tier 1: GPU HBM ────────────────────────────────── 1555 GB/s         │
│            │ 40GB × 4 = 160GB/노드                                      │
│            ▼ evict (async)                                              │
│   Tier 2: 로컬 SHM (mmap) ───────────────────────── 204 GB/s           │
│            │ /dev/shm, 256GB/노드                                       │
│            ▼ MPI 전송 (Slingshot-11)                                    │
│   Tier 3: 원격 SHM ──────────────────────────────── 22.8 GB/s          │
│            │ 다른 노드의 DRAM                                            │
│            ▼ async prefetch                                             │
│   Tier 4: Lustre PFS ────────────────────────────── 17 GB/s            │
│            $SCRATCH, 44PB, stripe 최적화                                 │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 📊 5개 시스템 비교 (Perlmutter 4노드, 500GB 데이터)

### 1. Lustre Cold Read 성능 (동일 조건)

> 모든 데이터가 Lustre에서 읽힐 때 (`posix_fadvise DONTNEED`)

| 시스템 | Write (GB/s) | Read (GB/s) | 특징 |
|--------|-------------|-------------|------|
| **PDC** | 6.75 | **17.74** | Per-file + fsync |
| **LMCache** | 6.72 | 17.46 | Per-file (기준선) |
| **Redis** | 6.56 | 17.29 | Per-file batch |
| **Cascade** | 6.00 | 16.92 | Aggregated + stripe |
| **HDF5** | 6.85 | 14.39 | 단일 파일 |

```
📌 핵심 발견: Lustre-only에서는 모든 시스템이 ~17 GB/s로 수렴
   → Cascade의 가치는 스토리지 포맷이 아닌 "계층적 캐싱"에 있음!
```

---

### 2. 🔥 Hot 데이터 시나리오 (SHM에 캐시됨)

> 자주 사용되는 prefix가 공유 메모리에 있을 때

| 시스템 | Hot Read | 설명 |
|--------|----------|------|
| **Cascade** | **160.9 GB/s** | mmap SHM 직접 접근 |
| LMCache | 145.4 GB/s | OS page cache |
| PDC | 135.6 GB/s | page cache |
| Redis | 2.6 GB/s | 네트워크 직렬화 |
| HDF5 | 25.5 GB/s | 압축 해제 오버헤드 |

```
┌──────────────────────────────────────────────────────────────────────┐
│                    Hot Read 성능 비교 (GB/s)                          │
├──────────────────────────────────────────────────────────────────────┤
│ Cascade  ████████████████████████████████████████████████ 160.9     │
│ LMCache  ██████████████████████████████████████████ 145.4           │
│ PDC      █████████████████████████████████████ 135.6                │
│ HDF5     ███████ 25.5                                                │
│ Redis    █ 2.6                                                       │
└──────────────────────────────────────────────────────────────────────┘
```

---

### 3. ❄️ Cold 데이터 시나리오 (Lustre에서 읽음)

> page cache가 비워진 상태에서 Lustre 직접 읽기

| 시스템 | Cold Read | 설명 |
|--------|----------|------|
| PDC | **17.74 GB/s** | Per-file 최적 |
| LMCache | 17.46 GB/s | Per-file |
| Redis | 17.29 GB/s | Per-file |
| **Cascade** | 16.92 GB/s | Aggregated file |
| HDF5 | 14.39 GB/s | 메타데이터 오버헤드 |

```
📌 Lustre cold에서 Cascade가 살짝 느린 이유:
   - 단일 aggregated file에서 seek() 오버헤드
   - 하지만 이건 문제가 아님! Hot 데이터는 SHM에서 서빙하기 때문
```

---

## 🏆 Cascade만의 차별점 (LMCache가 못하는 것)

### 1️⃣ Content-Addressed Deduplication (17.5배 스토리지 절약)

```
┌─────────────────────────────────────────────────────────────────────────┐
│                  100개 세션이 같은 System Prompt 공유                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  LMCache (세션별 ID):                                                    │
│  ┌──────┐ ┌──────┐ ┌──────┐     ┌──────┐                               │
│  │Prompt│ │Prompt│ │Prompt│ ... │Prompt│  = 100개 복사본 = 2100 MB     │
│  │ #1   │ │ #2   │ │ #3   │     │ #100 │                               │
│  └──────┘ └──────┘ └──────┘     └──────┘                               │
│                                                                         │
│  Cascade (SHA-256 해시):                                                 │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │              Prompt (SHA256: a1b2c3d4...)                         │  │
│  │                       1개 저장 = 120 MB                           │  │
│  └──────────────────────────────────────────────────────────────────┘  │
│                                                                         │
│  Session #1 ──┐                                                         │
│  Session #2 ──┼──→ 모두 같은 블록 참조                                   │
│  Session #100 ┘                                                         │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘

📊 결과: 2100 MB → 120 MB = 17.5배 절약!
```

| 시스템 | 저장 방식 | 100 세션 스토리지 | 절약률 |
|--------|----------|------------------|--------|
| LMCache | 세션별 ID | 2100 MB | 1.0× |
| **Cascade** | SHA-256 해시 | **120 MB** | **17.5×** |

---

### 2️⃣ 멀티노드 SHM 스케일링 (4배 대역폭)

```
┌─────────────────────────────────────────────────────────────────────────┐
│                       SHM 대역폭 스케일링                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  LMCache (싱글노드):                                                     │
│  ┌─────────┐                                                            │
│  │ Node 0  │──→ 13.6 GB/s (1노드 DDR4 한계)                             │
│  └─────────┘                                                            │
│                                                                         │
│  Cascade (MPI 연결):                                                     │
│  ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐                 │
│  │ Node 0  │───│ Node 1  │───│ Node 2  │───│ Node 3  │                 │
│  └─────────┘   └─────────┘   └─────────┘   └─────────┘                 │
│       │             │             │             │                       │
│       └─────────────┴─────────────┴─────────────┘                       │
│                        │                                                │
│                   54.3 GB/s (4노드 aggregate)                           │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

| 노드 수 | LMCache | Cascade | 스케일링 |
|--------|---------|---------|----------|
| 1 | 13.6 GB/s | 13.6 GB/s | 1× |
| 4 | 13.6 GB/s ❌ | **54.3 GB/s** | **4×** |
| 64 | 13.6 GB/s ❌ | ~800 GB/s (예상) | **~60×** |

---

### 3️⃣ 원격 DRAM Fetch via Slingshot (Lustre 대비 5.4배)

```
┌─────────────────────────────────────────────────────────────────────────┐
│              Node A에서 Node B의 캐시된 데이터 가져오기                   │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  LMCache (Lustre fallback):                                             │
│  ┌─────────┐                    ┌─────────┐                            │
│  │ Node A  │─────Lustre FS──────│ Node B  │                            │
│  └─────────┘   17 GB/s 😢       └─────────┘                            │
│                                                                         │
│  Cascade (Slingshot-11 MPI):                                            │
│  ┌─────────┐════════════════════┌─────────┐                            │
│  │ Node A  │   22.8 GB/s 🚀     │ Node B  │                            │
│  └─────────┘   (Slingshot-11)   └─────────┘                            │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

| Message 크기 | Per-Link 대역폭 | 4노드 Aggregate |
|-------------|----------------|-----------------|
| 1 MB | 1.05 GB/s | 4.2 GB/s |
| 64 MB | 20.82 GB/s | 83.3 GB/s |
| 512 MB | **22.78 GB/s** | **91.1 GB/s** |

**vs Lustre cold read (17 GB/s) = 5.4배 빠름!**

---

## 📈 시나리오별 성능 요약

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      시나리오별 최적 시스템 선택                          │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  100% Hot (SHM):    Cascade >> LMCache > PDC >> HDF5 >> Redis          │
│                     160 GB/s   145       136    25       3              │
│                                                                         │
│  100% Cold (Lustre): PDC ≈ LMCache ≈ Redis ≈ Cascade >> HDF5           │
│                      17.7   17.5     17.3    16.9       14.4           │
│                                                                         │
│  중복 세션:          Cascade >>>>>>>>>>>>>>>>>>>>> 나머지 전부           │
│                     17.5배 절약                    1배                  │
│                                                                         │
│  멀티노드:           Cascade >>>>>>>>>>>>>>>>>>>> 나머지 전부            │
│                     4배 스케일                    싱글노드 한계          │
│                                                                         │
│  원격 데이터:        Cascade >>>>> LMCache/PDC (Lustre로 fallback)      │
│                     22.8 GB/s     17 GB/s                              │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 🔑 핵심 결론

### Cascade vs 각 경쟁 시스템

| vs | Cascade 장점 | 수치 |
|----|-------------|------|
| **vs LMCache** | 멀티노드, Dedup, 원격 DRAM | 17.5× 스토리지, 4× 대역폭 |
| **vs PDC** | 더 빠른 Hot read, Dedup | 160 vs 136 GB/s (Hot) |
| **vs Redis** | 네트워크 병목 없음 | 160 vs 2.6 GB/s (Hot) |
| **vs HDF5** | CPU 압축 병목 없음 | 160 vs 25 GB/s (Hot) |
| **vs vLLM** | 멀티노드, 영속 캐시 | GPU 40GB → 무제한 |

### 언제 Cascade를 사용해야 하는가?

| 시나리오 | 추천 시스템 | 이유 |
|---------|------------|------|
| 싱글노드, 작은 데이터 | LMCache 충분 | 단순함 |
| **멀티노드 LLM 서빙** | **Cascade** | 유일한 선택 |
| **세션 간 prefix 공유** | **Cascade** | 17.5배 절약 |
| **HPC 클러스터** | **Cascade** | Slingshot 활용 |
| 과학 데이터 분석 | HDF5 | 표준 포맷 |

---

## 📋 벤치마크 재현

### 빠른 테스트 (5분)

```bash
# Cascade 고유 기능 벤치마크
sbatch benchmark/scripts/cascade_unique_bench.sh

# Slingshot 대역폭 테스트
sbatch benchmark/scripts/slingshot_bench.sh
```

### 전체 5개 시스템 비교 (30분)

```bash
# 500GB 대규모 테스트
sbatch benchmark/scripts/all5_large_bench.sh
```

---

## 📚 벤치마크 결과 (Job IDs)

| Job | 설명 | 핵심 결과 |
|-----|------|----------|
| 48415672 | 500GB 5개 시스템 Cold read | Lustre: 모두 ~17 GB/s |
| 48415750 | Dedup + 멀티노드 SHM | 17.5× 절약, 4× 스케일링 |
| 48415769 | Slingshot-11 대역폭 | 22.8 GB/s (5.4× vs Lustre) |
| 48414598 | Hot vs Cold tiered | Hot 160 GB/s, Cold 17 GB/s |

---

## 🏁 결론

> **"Cascade는 Lustre 스토리지 자체가 아닌, HPC-scale 계층적 캐싱에서 차별화된다."**

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    Cascade의 3가지 핵심 차별점                           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  1. Content-Addressed Deduplication ──────────── 17.5× 스토리지 절약   │
│     SHA-256 해시 기반, 세션 간 자동 공유                                 │
│                                                                         │
│  2. 멀티노드 SHM Aggregation ─────────────────── 4× 대역폭 (4노드)     │
│     MPI 기반 글로벌 주소 공간                                            │
│                                                                         │
│  3. Slingshot-11 원격 DRAM ───────────────────── 5.4× faster vs Lustre │
│     22.8 GB/s per link                                                  │
│                                                                         │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ⚠️  중요: Lustre cold read에서는 Cascade가 약간 느림 (16.9 vs 17.7)   │
│      → 하지만 Hot 데이터는 SHM에서 160 GB/s로 서빙!                      │
│      → 실제 워크로드에서는 Hot 비율이 높을수록 Cascade가 압도적 우위     │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

**LMCache가 할 수 없는 것들** — 이것이 Cascade의 존재 이유입니다.

---

## 📖 라이센스

SC'26 논문 제출용 연구 프로젝트
